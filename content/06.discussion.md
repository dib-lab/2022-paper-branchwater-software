## Discussion {.page_break_before}

Enabling content-based search of very large collections of sequencing data
is an open problem, and approaches that work for smaller collections
rarely scale well, even for current database sizes. New methods that
take advantage of specific particularities of the query and desired
answer can help bridge the gap between more general methods by
allowing filtering large databases, resulting in more manageable
subsets that can be used efficiently with current methods.

K-mer search via sourmash branchwater is a lightweight, scaleable
approach to content-based search of petabase-scale collections of
sequencing data. Branchwater is designed to recover data sets
with high nucleotide similarity to the query sequence (>90% ANI)
across petabases of sequence data using computational resources
available to many researchers. This approach is one of the few options
for searching the entire Sequence Read Archive, and we anticipate it
will be most useful for filtering large databases to generate a
manageable subset of relevant data sets that can be analyzed in
detail using other analysis tools.

Despite it's utility, branchwater search has several limitations, some
of which are intrinsic to the approach, and some of which can be
overcome with improved database storage and search design.
First, branchwater search relies upon exact matching of long nucleotide
k-mers, which work best for sequences with high sequence identity (90%+ ANI),
 particularly when combined with high thresholding used for fast search.
Approaches using alignment-based techniques may be more useful for
detecting similarity across larger evolutionary distances (cite Serratus).
Lumian et al. (2022) validated branchwater results by downloading
matching Illumina metagenomes above a specific containment threshold
and mapping the reads back to the query genomes to evaluate both
mapping detection and effective coverage. In all but one case,
k-mer-based genome detection of the query was well below mapping-based
detection - in some cases significantly so. This was also seen with a
other samples in Irber et al., 2022 [@gather], and is likely because
mapping-based approaches can tolerate mismatches, while k-mer based
approaches do not.

Second, as designed, branchwater cannot robustly detect sequence similarity for
data sets under 10kb in size. This limit is related to the scaling approach
used to reduce the effective search space and enable petabase-scale search.
Branchwater leverages FracMinHash sketching to build a reduced representation of each
data set, whicch enables direct and accurate sequence similarity and containment
comparisons without needing to access the original sequencing reads.
Because only a fraction of the original data needs to be
stored, FracMinHash sketches are good basic components in the implementation of
systems that allow searching large collections of datasets.
However, this approach comes with some detection limitations.
Robust detection requires a minimum overlap of 2-3 k-mers
(hashes) [@gather]. With the scaling used in branchwater, this represents
approximately 2-3 kb of matching sequence.
Since many plasmids and most bacterial and archaeal genomes
are far larger than 10kb, branchwater is well suited to detecting
matches to such sequences in the SRA.
Future storage and search optimizations may enable higher resolution
search, but for now, sequences smaller than 10kb may be missed a
as a result of this fractional k-mer selection.

### Tackling biological use cases with branchwater

K-mer search via branchwater has been used in two papers so far -
Lumian et al. (2022) [@lumian_biogeo] and Viehweger et al. (2021)
[@viehweger]. Viehweger et al. used branchwater to find a metagenome
containing an additional *Klebsiella pneumoniae* for a large scale
analysis of outbreak data, while Lumian et al. conducted a global
biogeography analysis of five new antarctic cyanobacteria. Both
studies benefitted from the low cost and comprehensive nature of the
search.

We expect more use cases, and more elaborate use cases, to emerge as
petabase scale search improves. The low cost of search is particularly
enabling for exploratory efforts, although the sheer size of the
underlying data needed for branchwater continues to present
obstacles. We are planning to focus on realtime API access to search
methods.

There are several scientific limitations to overcome as well. The
current search approach has limited sensitivity to divergent sequence
beyond the genus level, and cannot find smaller matches. These are
topics for future research and development.

### Following up on Branchwater results

Many Branchwater use cases are intended for early-stage hypothesis
generation and refinement, i.e. branchwater implements the first part
of a “hit to lead” pipeline. Hence Branchwater operates at an early
stage in conceptual and concrete workflows. The initial steps
immediately after executing Branchwater are (1) choosing a threshold
at which to filter results, (2) evaluating the overall results by type
of metagenome retrieved, and (3) retrieving the data underlying the
matches.

The first analysis step taken is typically picking a more stringent
threshold. The default Branchwater threshold is set to 0.01
containment - any metagenome that contains more than 1% of the k-mers
in any query is reported. This is done because searches are exhaustive
- every query is searched against every subject - and so there is no extra
cost beyond the minimal space required to save the results.

Thresholds are typically chosen based on the use case and the expected
distribution of the annotated metagenome type (`ScientificName` from
the SRA Runinfo database). We have provided a simple script that
imports the SRA metadata and summarizes the Branchwater results at the
provided threshold (example output).

After filtering, many paths can be taken. A plethora of general
purpose bioinformatics tools exist for working with the data from
individual metagenomes.

We have built two custom tools in concert with sourmash and
Branchwater, genome-grist and spacegraphcats.  Genome-grist performs
an entirely automated reference-based characterization of individual
metagenomes that combines sourmash gather / minimum metagenome cover
with mapping; it is described in Irber et al. [@gather] and was used
in Lumian et al. [@lumian_biogeo]. Given that it does download all the
data and maps all the reads, it is still relatively lightweight.

spacegraphcats is an assembly-graph based investigative tool for
metagenomes that retrieves graph neighborhoods from metagenome
assembly graphs for the purpose of investigating strain variation
[@spacegraphcats]. It was used to retrieve putative accessory elements
from sourmash matches in Reiter et al. [@reiter_ibd] and Lumian et
al. [@lumian_phormidium]. It is much heavier weight than genome-grist
because it relies on a compact De Bruijn graph, which is expensive to
build for very rich or diverse metagenomes.

### Design alternatives

Brancwhater is a simple and effective implementation that is easy to
analyze algorithmically and supports a number of use cases. However,
many improvements are possible: FracMinHash analyses are based on
comparing collections of 64-bit integers, and there are many effective
tools and approaches for organizing and searching such collections
more efficiently than is presently done in Branchwater.

One area for particular improvement is storing and loading sketches
more efficiently. The current JSON-based format is convenient for
debugging and multi-language interoperability but is extremely
inefficient, to put it mildly. Moreover, each file currently contains
three k-mer sketches (one per k-mer size), which means approximately 3
times as much data is loaded per query than is actually used.
FracMinHash also could support fractional loading, i.e. decreased
resolution by loading only the bottom portion of the sketch; this
would enable must faster searches albeit at lower resolution. This is
not yet supported by the underlying sourmash library.

Currently the data files are organized as flat files in a single
directory on a single network file system. There are a variety of
practical ways to speed up the search by distributing sketch files
across multiple nodes, but this is logistically challenging. In
particular, our typical usage involves running branchwater once every
few weeks on our HPC, which does not have sufficient local storage to
distribute the data sets. In addition, the speed savings from
distributing sketches across nodes is unlikely to be rewarding enough
to offset the maintenance requirements for a distributed collection of
13 TB of sketches.  Future work could include implementation of an
automated distribution system, although careful evaluation of the
maintenance and update requirements would be needed.

We could also create a simple pre-filter for each file using a data
structure with one-sided error. For example, we could create a Bloom
filter for each sketch that could be used to estimate containment
prior to loading the full sketch file. However, for some potentially
common use cases such as queries with many matches, this could add
significant I/O without speeding up the actual search.

Building an inverted index that maps hashes to data sets could also
enable rapid queries. Two challenges here are the scale of the catalog
and the number of data sets; the total number of hashes present in our
metagenome catalog is XYZ, across nearly 800,000 data sets.

Despite these many opportunities for optimization, we note that there
is a significant benefit to the simplicit of our current approach. In
particular, providing the sketches in individual files organized by
accession makes it straightforward to access individual sketches by a
distinct ID and quickly update the overall metagenome catalog.  This
is particularly valuable since the sourmash Python package provides a
flexible suite of tools for inspecting and manipulating individual
metagenome sketches.  The lack of auxiliary data structures also
avoids expensive load and synchronization steps when adding new
datasets. These features are important for downstream user
investigation as well as maintainability and correctness, which are
important considerations in any scientific software workflow.

## Conclusion {.page_break_before}

We provide a flexible and fast petabase-scale search based on
FracMinHash, together with some simple downstream summarization tools
and an increasingly mature (but much slower) investigative ecosystem.
This supports and enables a wide range of interesting use cases that
take advantage of public data; these use cases range from biomedical
to ecological to technical (Table @tbl:bio-use-cases).

## Data availability statement:

All of the original data underlying the Branchwater database is
available from the NCBI Sequence Read Archive. A current catalog of
the SRA accessions is provided (here). The sketch collection is 7 TB
and is available upon request.  All sketches are provided under
Creative Commons Zero (CC0) - No Rights Reserved.
