## Methods {.page_break_before}

XXX diagram

<!-- *The Methods should include a subsection on Implementation describing
 how the tool works and any relevant technical details required for
 implementation; and a subsection on Operation, which should include
 the minimal system requirements needed to run the software and an
 overview of the workflow.* -->

### Sketching the Sequence Read Archive

We determined the accessions of all publicly available shotgun
metagenomic via the query string `"METAGENOMIC"[Source] NOT
amplicon[All Fields]` at the NCBI Sequence Read Archive Web site,
https://www.ncbi.nlm.nih.gov/sra.  We then downloaded all runs for all
accessions and streamed them into `sourmash sketch dna` with
parameters `-p k=21,31,51,scaled=1000,abund`. The output sourmash
signature files were saved as individual gzipped JSON files (each
containing 3 sketches), one file for each input run.

The resulting catalog contains 767,277 metagenome data sets as of
March 2022, with the largest category annotated as human-associated microbiomes
(Table @tbl:sra-types). The size of all sketches together is 7.5 TB,
containing approximately 375 billion hashes per k-mer size,
representing 375 trillion k-mers <!-- from ZZZ PB of original files CTB -->. The
average sketch file size is 9.7 MB, and the median file size is 570kb. The
largest 10,000 data sets comprise 30% of the total sketch sizes.
<!-- NTP question: how big is largest sketch? XXX -->

| "Scientific Name" provided by submitter | distinct data sets |
| --- | --- |
| human gut metagenome  |   162187 |
| metagenome              |   57048
| gut metagenome           | 47244
| human metagenome         | 36438
| soil metagenome          | 35323
| mouse gut metagenome     | 26482
| human skin metagenome    | 25700
| Homo sapiens             | 21020
| marine metagenome        |14400
| human oral metagenome    |  14235

Table: The 10 largest categories of metagenome data set types in the Sequence
Read Archive, as of March 2022. {#tbl:sra-types}

### Implementation of multithreaded search

<!-- CTB: rename program to branchwater? -->

The `sra_search` program is built in Rust on top of the sourmash
library for loading and comparing sketches. It implements the
following steps:

1. Loads all query sketches into memory from a list of files.
2. Loads the list of filenames containing subject sketches to search.
3. In a Rust closure function executed in parallel for each subject sketch filename,
   a. loads the subject sketch from the file;
   b. for each query, determines the estimated overlap between query and subject;
   c. reports overlaps above a user-specified threshold.
   d. releases all per-metagenome resources

Downsampling of sketches to higher scaled values is performed
dynamically, after load (if requested). Results are reported back to a
separate "writer" thread via a threadsafe multi-producer,
single-consumer FIFO queue. We use the rayon `par_iter` function to
execute the closures in parallel.

This approach leverages the core features of sourmash to efficiently
keep queries in memory and batch-process metagenome sketches without
storing them all in memory. The approach also takes advantage of the
effective immutability of queries, which can be shared without
data races by multiple processing threads.

### Executing sra_search at the command line

`sra_search` takes in search parameters as well as two text files, one
containing a list of query file paths and one containing a list of
subject file paths. Upon execution, it reports the number of query
sketches loaded and the number of subject file paths found, and then
begins the search. It progressively reports the number of sketches
searched in blocks of 10000, and outputs matches to a CSV File.

We typically run `sra_search` in a snakemake workflow, which manages
environment variables and input/output files.

### Performance and scaling analysis

Benchmarks TODO:

* Do a benchmark of a complete query against all.
* Biggest sketches are much slower.

XXX make a table with 10k-normalized time and memory for entire catalog,
largest 30%, and random sample.

`sra_search` is largely I/O bound, with substantial input
requirements; this is particularly clear from the YYY% slowdown from
loading the 10,000 biggest sketches. 
`sra_search` scales linearly in memory and time with queries and number of threads.

| metric | observed | 
| -------- | -------- | 
| time     | 24.2 +/- 1.7 min |
| max RSS | 16.4 +/-  1.6 GB |
| I/O in | 93.4 +/- 1.9 GB |

Table: Time, memory, and I/O input for 5 runs of 1000 queries against 10,000 metagenomes. Queries were randomly selected from 318k genomes in GTDB rs207. Metagenomes were randomly selected from the full catalog of 767k.

![**branchwater scales well with number of threads.** Processing time drops linearly with number of threads, while total compute stays approximately the same and memory usage increases linearly with number of threads as each thread loads a subject to search.](images/basic_benchmarks.svg "basic benchmarking"){#fig:basic_bench}

CTB: should note that one thread is used exclusively for writing to CSV.

See https://github.com/dib-lab/2022-branchwater-benchmarking for
numbers and notebook.

![**branchwater scales linearly with number of queries and subjects, but number of subjects dominates runtime.** Processing time increases slowly with number of query genomes used to search, because they are held in memory and fast to compare. Processing time increases quickly with number of subject metagenomes being searched, because they are large and slow to load and search.](images/subsample_benchmarks.svg "branchwater scaling"){#fig:basic_scaling}

### Post-search validation

The sourmash CLI can be used to explore k-mer matches for individual
data sets. This does not validate the matches beyond confirming the
containment numbers, although sourmash provides additional information
(e.g. estimated abundances) on top of the minimal information
provided by branchwater.  FracMinHash generally and Branchwater
specifically have been validated bioinformatically primarily by
mapping reads (see [@gather; @lumian_biogeo]). This is discussed
further below.

### Sra_search is inexpensive and supports exploratory queries

CTB: Estimate cost of a run. Compare to serratus - cloud compute, data
download. Serratus is probably cheaper than $20k now but still
expensive.
